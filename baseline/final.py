import os, json, re, time, ast
import asyncio
from collections import deque
from datetime import datetime, timezone, timedelta
import pandas as pd
from dotenv import load_dotenv
from tqdm import tqdm
from langchain_google_genai import ChatGoogleGenerativeAI
from prompt import prompt
import csv
# code xá»­ lÃ½ tiáº¿p cÃ¡c báº£n ghi cÃ³ prediction rá»—ng
load_dotenv()

# Láº¥y tá»‘i Ä‘a 11 API keys tá»« biáº¿n mÃ´i trÆ°á»ng GOOGLE_API_KEY_1..11 (lá»c None/rá»—ng)
raw_api_keys = [os.getenv(f"GOOGLE_API_KEY_{i}") for i in range(1, 12)]
api_keys = [k for k in raw_api_keys if k and str(k).strip()]
if not api_keys:
    raise RuntimeError("KhÃ´ng tÃ¬m tháº¥y API key nÃ o trong biáº¿n mÃ´i trÆ°á»ng GOOGLE_API_KEY_1..11")

label_map = {
    "Public transports": 0,
    "Private modes": 1,
    "Soft modes": 2
}

# Äá»c dá»¯ liá»‡u gá»‘c
df = pd.read_csv("data/Optima/test.csv")
df["id"] = df.index  # lÆ°u láº¡i chá»‰ sá»‘ dÃ²ng gá»‘c

# Äá»c/khá»Ÿi táº¡o káº¿t quáº£ hiá»‡n táº¡i
result_path = "results/result5.csv"
process_all = False
try:
    result_df = pd.read_csv(result_path)
    if 'id' not in result_df.columns or 'prediction' not in result_df.columns:
        raise ValueError("result5.csv khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng")
    # TÃ¬m cÃ¡c báº£n ghi cÃ³ prediction rá»—ng
    empty_predictions = result_df[result_df['prediction'].isna() | (result_df['prediction'] == '')]
    print(f"TÃ¬m tháº¥y {len(empty_predictions)} báº£n ghi cÃ³ prediction rá»—ng")
    if len(empty_predictions) == 0:
        # Náº¿u khÃ´ng cÃ²n rá»—ng, khÃ´ng cáº§n xá»­ lÃ½ thÃªm
        print("KhÃ´ng cÃ³ báº£n ghi nÃ o cáº§n xá»­ lÃ½ láº¡i!")
        # KhÃ´ng exit Ä‘á»ƒ cÃ³ thá»ƒ há»— trá»£ cháº¡y toÃ n táº­p náº¿u ngÆ°á»i dÃ¹ng xÃ³a file rá»“i cháº¡y láº¡i
        rows_to_process = []
    else:
        empty_ids = empty_predictions['id'].tolist()
        rows_to_process = df[df['id'].isin(empty_ids)].to_dict(orient="records")
        print(f"Sáº½ xá»­ lÃ½ láº¡i {len(rows_to_process)} báº£n ghi")
except Exception:
    # File chÆ°a tá»“n táº¡i hoáº·c khÃ´ng há»£p lá»‡ â†’ khá»Ÿi táº¡o má»›i vÃ  xá»­ lÃ½ toÃ n bá»™ test
    os.makedirs(os.path.dirname(result_path), exist_ok=True)
    base = {
        'id': df['id'],
        'prediction': [''] * len(df)
    }
    if 'CHOICE' in df.columns:
        base['CHOICE'] = df['CHOICE']
    else:
        base['CHOICE'] = [None] * len(df)
    result_df = pd.DataFrame(base)
    result_df.to_csv(result_path, index=False)
    rows_to_process = df.to_dict(orient="records")
    process_all = True
    print(f"Khá»Ÿi táº¡o {result_path}. Sáº½ xá»­ lÃ½ toÃ n bá»™ {len(rows_to_process)} báº£n ghi trong test.csv")

def safe_parse_json(raw: str):
    if raw is None or not str(raw).strip():
        raise ValueError("Empty model response")
    text = str(raw).strip()
    text = re.sub(r"^```(?:json)?\s*|\s*```$", "", text, flags=re.IGNORECASE | re.MULTILINE)
    try:
        return json.loads(text)
    except Exception:
        # Cá»‘ gáº¯ng tÃ¬m Ä‘oáº¡n JSON trong chuá»—i dÃ i
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1 and end > start:
            candidate = text[start:end + 1]
            # Thá»­ parse JSON chuáº©n trÆ°á»›c
            try:
                return json.loads(candidate)
            except Exception:
                pass
            # Fallback: parse kiá»ƒu dict Python vá»›i nhÃ¡y Ä‘Æ¡n báº±ng ast.literal_eval
            try:
                data = ast.literal_eval(candidate)
                if isinstance(data, dict):
                    return data
            except Exception:
                pass
        # Fallback cuá»‘i: thá»­ literal_eval toÃ n bá»™ vÄƒn báº£n
        try:
            data = ast.literal_eval(text)
            if isinstance(data, dict):
                return data
        except Exception:
            pass
        # Heuristic cuá»‘i: cá»‘ gáº¯ng trÃ­ch xuáº¥t nhÃ£n dá»± Ä‘oÃ¡n tá»« text tá»± do
        try:
            # TÃ¬m pattern prediction: <label> hoáº·c chá»‰ cÃ³ label Ä‘á»©ng riÃªng láº»
            m = re.search(r"prediction\s*[:=\-\s]+(Public transports|Private modes|Soft modes)", text, flags=re.IGNORECASE)
            if not m:
                # TÃ¬m label Ä‘á»©ng riÃªng láº» (cÃ³ thá»ƒ lÃ  toÃ n bá»™ response)
                m = re.search(r"\b(Public transports|Private modes|Soft modes)\b", text, flags=re.IGNORECASE)
            if m:
                label = m.group(1).strip()
                return {"prediction": label}
        except Exception:
            pass
        # Náº¿u táº¥t cáº£ Ä‘á»u tháº¥t báº¡i, nÃ©m lá»—i gá»‘c Ä‘á»ƒ hiá»ƒn thá»‹ thÃ´ng tin
        raise

class PerKeyRateLimiter:
    def __init__(self, key: str, per_minute_limit: int = 5, per_day_limit: int = 100):
        self.key = key
        self.per_minute_limit = per_minute_limit
        self.per_day_limit = per_day_limit
        self.minute_window = deque()  # timestamps giÃ¢y trong 60s gáº§n nháº¥t
        self.day_count = 0
        self.day_anchor = self._current_day_anchor()
        self.lock = asyncio.Lock()

    def _current_day_anchor(self) -> str:
        return datetime.now(timezone.utc).date().isoformat()

    def _reset_day_if_needed(self):
        current = self._current_day_anchor()
        if current != self.day_anchor:
            self.day_anchor = current
            self.day_count = 0

    def _prune_minute_window(self, now_ts: float):
        cutoff = now_ts - 60.0
        while self.minute_window and self.minute_window[0] <= cutoff:
            self.minute_window.popleft()

    async def wait_for_slot(self):
        while True:
            async with self.lock:
                now_ts = time.time()
                self._reset_day_if_needed()
                self._prune_minute_window(now_ts)

                minute_used = len(self.minute_window)
                day_used = self.day_count

                if day_used >= self.per_day_limit:
                    # ngá»§ Ä‘áº¿n Ä‘áº§u ngÃ y UTC tiáº¿p theo
                    now_dt = datetime.now(timezone.utc)
                    next_day = (now_dt + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                    sleep_s = max(1.0, (next_day - now_dt).total_seconds())
                elif minute_used < self.per_minute_limit:
                    self.minute_window.append(now_ts)
                    self.day_count += 1
                    return
                else:
                    oldest = self.minute_window[0]
                    sleep_s = max(0.0, 60.0 - (now_ts - oldest)) + 0.01
            await asyncio.sleep(sleep_s)

class ApiKeyPool:
    def __init__(self, api_keys_list, per_minute_limit: int = 5, per_day_limit: int = 100):
        self.limiters = [PerKeyRateLimiter(k, per_minute_limit, per_day_limit) for k in api_keys_list]
        self.idx = 0
        self.pool_lock = asyncio.Lock()

    async def acquire(self) -> PerKeyRateLimiter:
        while True:
            # xoay vÃ²ng key Ä‘á»ƒ trÃ¡nh starvation
            async with self.pool_lock:
                start = self.idx
                order = list(range(len(self.limiters)))
                order = order[start:] + order[:start]

            # thá»­ láº¥y slot ngay
            for i in order:
                limiter = self.limiters[i]
                if await self._try_immediate(limiter):
                    async with self.pool_lock:
                        self.idx = (i + 1) % len(self.limiters)
                    return limiter

            # náº¿u khÃ´ng cÃ³ slot ngay, chá» ngáº¯n rá»“i thá»­ láº¡i
            await asyncio.sleep(0.05)

    async def _try_immediate(self, limiter: PerKeyRateLimiter) -> bool:
        now_ts = time.time()
        async with limiter.lock:
            limiter._reset_day_if_needed()
            limiter._prune_minute_window(now_ts)
            if limiter.day_count >= limiter.per_day_limit:
                return False
            if len(limiter.minute_window) < limiter.per_minute_limit:
                limiter.minute_window.append(now_ts)
                limiter.day_count += 1
                return True
            return False

async def call_model_async(index, total, row, api_key, retries=3, delay=10):
    # Táº¡o model theo key má»—i láº§n gá»i Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t state giá»¯a threads
    def _do_invoke(prompt_text: str):
        model = ChatGoogleGenerativeAI(model="gemini-2.5-pro", google_api_key=api_key)
        return model.invoke(prompt_text)

    for attempt in range(retries):
        try:
            prompt_text = prompt(row)
            print(f"[{index+1}/{total}] ğŸ” Äang xá»­ lÃ½ láº¡i row id={row['id']}...")
            response = await asyncio.to_thread(_do_invoke, prompt_text)
            raw = str(getattr(response, "content", response))

            try:
                prediction_dict = safe_parse_json(raw)
            except Exception as pe:
                print(f"[{index+1}] âŒ JSON parse failed for id={row.get('id','N/A')}: {pe}")
                with open("errors.log", "a") as f:
                    f.write(f"JSON parse failed at index {index} (id={row.get('id','N/A')}): {pe}\nRAW:\n{raw}\n\n")
                return row.get("id", index), None, row.get("CHOICE", None)

            prediction_str = (prediction_dict.get("prediction") or "").strip()
            print(f"[{index+1}] âœ… HoÃ n táº¥t row id={row['id']} â†’ {prediction_str}")
            return row["id"], label_map.get(prediction_str, None), row.get("CHOICE", None)
        except Exception as e:
            if ("429" in str(e) or "rate" in str(e).lower()) and attempt < retries - 1:
                print(f"[{index+1}] â³ Lá»—i 429/rate limit. Äá»£i {delay}s rá»“i thá»­ láº¡i...")
                await asyncio.sleep(delay)
            else:
                print(f"[{index+1}] âŒ Lá»—i á»Ÿ row id={row.get('id', 'N/A')}: {e}")
                with open("errors.log", "a") as f:
                    f.write(f"Lá»—i á»Ÿ dÃ²ng {index} (id={row.get('id', 'N/A')}): {e}\n")
                return row.get("id", index), None, row.get("CHOICE", None)

async def worker(name, pool: ApiKeyPool, jobs_q: asyncio.Queue, result_df, result_path: str, total: int, df_lock: asyncio.Lock, progress_state: dict, progress_lock: asyncio.Lock):
    while True:
        item = await jobs_q.get()
        if item is None:
            jobs_q.task_done()
            break

        limiter = await pool.acquire()
        key = limiter.key
        try:
            result = await call_model_async(item[0], total, item[1], key)
            # cáº­p nháº­t káº¿t quáº£ vÃ  lÆ°u file an toÃ n
            async with df_lock:
                result_df.loc[result_df['id'] == result[0], 'prediction'] = result[1]
                # Cáº­p nháº­t CHOICE náº¿u cÃ²n trá»‘ng vÃ  cÃ³ trong dá»¯ liá»‡u Ä‘áº§u vÃ o
                if 'CHOICE' in result_df.columns and 'CHOICE' in item[1]:
                    if pd.isna(result_df.loc[result_df['id'] == result[0], 'CHOICE']).any() or (result_df.loc[result_df['id'] == result[0], 'CHOICE'] == '').any():
                        result_df.loc[result_df['id'] == result[0], 'CHOICE'] = item[1].get('CHOICE')
                result_df.to_csv(result_path, index=False)
                print(f"âœ… ÄÃ£ cáº­p nháº­t id={result[0]} vá»›i prediction={result[1]}")
            # cáº­p nháº­t tiáº¿n Ä‘á»™ vÃ  in pháº§n trÄƒm
            async with progress_lock:
                progress_state['done'] += 1
                done = progress_state['done']
                percent = (done / total) * 100 if total else 100.0
                print(f"ğŸ“ˆ Tiáº¿n Ä‘á»™: {done}/{total} ({percent:.2f}%)")
        finally:
            jobs_q.task_done()

async def run_all(rows, result_df, result_path: str, api_keys_list, max_workers: int = None):
    total = len(rows)
    if max_workers is None:
        # Cháº¡y tuáº§n tá»± vá»›i 1 worker Ä‘á»ƒ dÃ¹ng láº§n lÆ°á»£t cÃ¡c key
        max_workers = 1

    pool = ApiKeyPool(api_keys_list, per_minute_limit=5, per_day_limit=100)
    jobs_q: asyncio.Queue = asyncio.Queue()
    for i, row in enumerate(rows):
        await jobs_q.put((i, row))
    for _ in range(max_workers):
        await jobs_q.put(None)

    df_lock = asyncio.Lock()
    progress_state = {'done': 0}
    progress_lock = asyncio.Lock()
    workers = [
        asyncio.create_task(
            worker(
                f"worker-{i+1}",
                pool,
                jobs_q,
                result_df,
                result_path,
                total,
                df_lock,
                progress_state,
                progress_lock,
            )
        )
        for i in range(max_workers)
    ]
    await jobs_q.join()
    for w in workers:
        w.cancel()
    await asyncio.gather(*workers, return_exceptions=True)

# Cáº­p nháº­t káº¿t quáº£
print("Báº¯t Ä‘áº§u xá»­ lÃ½ láº¡i cÃ¡c báº£n ghi cÃ³ prediction rá»—ng...")

# Cháº¡y tuáº§n tá»± vá»›i 1 worker Ä‘á»ƒ dÃ¹ng láº§n lÆ°á»£t cÃ¡c key
asyncio.run(run_all(rows_to_process, result_df, result_path, api_keys, max_workers=1))

print(f"âœ… HoÃ n táº¥t xá»­ lÃ½ láº¡i. Káº¿t quáº£ cáº­p nháº­t táº¡i: {result_path}")

# Kiá»ƒm tra láº¡i xem cÃ²n báº£n ghi nÃ o rá»—ng khÃ´ng
final_check = result_df[result_df['prediction'].isna() | (result_df['prediction'] == '')]
if len(final_check) > 0:
    print(f"âš ï¸ Váº«n cÃ²n {len(final_check)} báº£n ghi cÃ³ prediction rá»—ng: {final_check['id'].tolist()}")
else:
    print("ğŸ‰ Táº¥t cáº£ báº£n ghi Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ thÃ nh cÃ´ng!")
