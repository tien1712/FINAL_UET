import os
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from dotenv import load_dotenv
load_dotenv()

# --- Config ---
CSV_PATH = "data/Optima/train.csv"       # file c·ªßa b·∫°n
FAISS_FOLDER = "db/faiss_index"

# --- API Keys Management ---
API_KEYS = [
    os.getenv("GOOGLE_API_KEY_9"),
    os.getenv("GOOGLE_API_KEY_2"), 
    os.getenv("GOOGLE_API_KEY_3"),
    os.getenv("GOOGLE_API_KEY_4"),
    os.getenv("GOOGLE_API_KEY_5"),
    os.getenv("GOOGLE_API_KEY_6"),
    os.getenv("GOOGLE_API_KEY_8")
]

# Rate limiting config
REQUESTS_PER_MINUTE = 100
REQUESTS_PER_KEY = 1000

# --- Load data ---
df = pd.read_csv(CSV_PATH)
texts = df['INFOR'].fillna("").astype(str).tolist()
metadatas = [{"id": int(row["ID"]), "choice": int(row["CHOICE"])} for _, row in df.iterrows()]

# --- Rate Limiting Manager ---
class RateLimitManager:
    def __init__(self, api_keys, requests_per_minute=100, requests_per_key=1000):
        self.api_keys = [key for key in api_keys if key is not None]
        self.requests_per_minute = requests_per_minute
        self.requests_per_key = requests_per_key
        
        # Tracking variables
        self.current_key_index = 0
        self.key_usage_count = {i: 0 for i in range(len(self.api_keys))}
        self.key_request_times = {i: [] for i in range(len(self.api_keys))}  # Track per key
        self.embedding_models = {}
        self.rate_limited_keys = set()  # Keys ƒëang b·ªã rate limit
        
        print(f"‚úÖ Kh·ªüi t·∫°o v·ªõi {len(self.api_keys)} API keys")
    
    def get_embedding_model(self, key_index):
        """L·∫•y embedding model cho key c·ª• th·ªÉ"""
        if key_index not in self.embedding_models:
            self.embedding_models[key_index] = GoogleGenerativeAIEmbeddings(
                model="models/gemini-embedding-001",
                google_api_key=self.api_keys[key_index]
            )
        return self.embedding_models[key_index]
    
    def get_current_embedding_model(self):
        """L·∫•y embedding model hi·ªán t·∫°i"""
        return self.get_embedding_model(self.current_key_index)
    
    def is_key_available(self, key_index):
        """Ki·ªÉm tra key c√≥ s·∫µn s√†ng s·ª≠ d·ª•ng kh√¥ng"""
        current_time = datetime.now()
        
        # Ki·ªÉm tra rate limit per minute cho key n√†y
        key_times = self.key_request_times[key_index]
        key_times = [t for t in key_times if current_time - t < timedelta(minutes=1)]
        self.key_request_times[key_index] = key_times
        
        # Ki·ªÉm tra usage per key
        if self.key_usage_count[key_index] >= self.requests_per_key:
            return False, "quota_exceeded"
        
        # Ki·ªÉm tra rate limit per minute
        if len(key_times) >= self.requests_per_minute:
            return False, "rate_limited"
        
        return True, "available"
    
    def find_best_available_key(self):
        """T√¨m key t·ªët nh·∫•t c√≥ th·ªÉ s·ª≠ d·ª•ng"""
        available_keys = []
        
        for key_index in range(len(self.api_keys)):
            is_available, reason = self.is_key_available(key_index)
            if is_available:
                # ∆Øu ti√™n key c√≥ √≠t requests nh·∫•t trong ph√∫t v·ª´a r·ªìi
                usage_score = len(self.key_request_times[key_index])
                available_keys.append((key_index, usage_score))
        
        if available_keys:
            # S·∫Øp x·∫øp theo usage score (√≠t nh·∫•t tr∆∞·ªõc)
            available_keys.sort(key=lambda x: x[1])
            best_key = available_keys[0][0]
            self.current_key_index = best_key
            return self.get_embedding_model(best_key)
        
        return None  # Kh√¥ng c√≥ key n√†o available
    
    def switch_to_next_key(self):
        """Chuy·ªÉn sang key ti·∫øp theo c√≥ s·∫µn"""
        # Th·ª≠ t√¨m key t·ªët nh·∫•t
        model = self.find_best_available_key()
        if model:
            print(f"üîÑ Chuy·ªÉn sang API key {self.current_key_index + 1}")
            return model
        
        # N·∫øu kh√¥ng c√≥ key n√†o available, ch·ªù key ƒë·∫ßu ti√™n
        print("‚è≥ T·∫•t c·∫£ keys ƒë·ªÅu b·ªã rate limit, ch·ªù key ƒë·∫ßu ti√™n...")
        first_key = 0
        self.current_key_index = first_key
        
        # T√≠nh th·ªùi gian ch·ªù cho key ƒë·∫ßu ti√™n
        key_times = self.key_request_times[first_key]
        if key_times:
            oldest_request = min(key_times)
            wait_time = 60 - (datetime.now() - oldest_request).total_seconds()
            if wait_time > 0:
                print(f"‚è≥ Ch·ªù {wait_time:.1f}s cho key {first_key + 1}...")
                time.sleep(wait_time)
                self.key_request_times[first_key] = []
        
        return self.get_embedding_model(first_key)
    
    def check_rate_limits(self):
        """Ki·ªÉm tra v√† x·ª≠ l√Ω rate limits - t·ªëi ∆∞u ƒë·ªÉ chuy·ªÉn key ngay l·∫≠p t·ª©c"""
        # Ki·ªÉm tra key hi·ªán t·∫°i c√≥ available kh√¥ng
        is_available, reason = self.is_key_available(self.current_key_index)
        
        if not is_available:
            if reason == "rate_limited":
                print(f"‚ö° Key {self.current_key_index + 1} b·ªã rate limit, chuy·ªÉn ngay sang key kh√°c...")
            elif reason == "quota_exceeded":
                print(f"üîÑ Key {self.current_key_index + 1} ƒë√£ h·∫øt quota, chuy·ªÉn sang key kh√°c...")
            
            return self.switch_to_next_key()
        
        return self.get_current_embedding_model()
    
    def record_request(self):
        """Ghi nh·∫≠n m·ªôt request cho key hi·ªán t·∫°i"""
        current_time = datetime.now()
        self.key_request_times[self.current_key_index].append(current_time)
        self.key_usage_count[self.current_key_index] += 1
    
    def get_status(self):
        """L·∫•y th√¥ng tin tr·∫°ng th√°i hi·ªán t·∫°i"""
        current_time = datetime.now()
        key_status = {}
        
        for key_idx in range(len(self.api_keys)):
            # T√≠nh requests trong ph√∫t v·ª´a r·ªìi cho m·ªói key
            recent_requests = [t for t in self.key_request_times[key_idx] 
                             if current_time - t < timedelta(minutes=1)]
            
            is_available, reason = self.is_key_available(key_idx)
            key_status[key_idx] = {
                "usage": self.key_usage_count[key_idx],
                "requests_last_minute": len(recent_requests),
                "available": is_available,
                "reason": reason if not is_available else "available"
            }
        
        return {
            "current_key": self.current_key_index + 1,
            "key_status": key_status,
            "total_available_keys": sum(1 for status in key_status.values() if status["available"])
        }

# Kh·ªüi t·∫°o rate limit manager
rate_manager = RateLimitManager(API_KEYS, REQUESTS_PER_MINUTE, REQUESTS_PER_KEY)

# --- Build FAISS in batches with rate limiting ---
def build_faiss_in_batches(texts, metadatas, rate_manager, faiss_folder, batch_size=20):
    db = None
    total_requests = 0
    
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        batch_metas = metadatas[i:i+batch_size]
        
        # Ki·ªÉm tra rate limits tr∆∞·ªõc khi x·ª≠ l√Ω batch
        embedding_model = rate_manager.check_rate_limits()
        
        try:
            # X·ª≠ l√Ω batch v·ªõi retry logic
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    batch_db = FAISS.from_texts(
                        texts=batch_texts,
                        embedding=embedding_model,
                        metadatas=batch_metas
                    )
                    
                    # Ghi nh·∫≠n requests (∆∞·ªõc t√≠nh s·ªë l∆∞·ª£ng requests d·ª±a tr√™n batch size)
                    for _ in range(len(batch_texts)):
                        rate_manager.record_request()
                        total_requests += 1
                    
                    break  # Th√†nh c√¥ng, tho√°t kh·ªèi retry loop
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói batch {i//batch_size + 1}, attempt {attempt + 1}: {str(e)}")
                    if attempt < max_retries - 1:
                        # Chuy·ªÉn sang key kh√°c n·∫øu c√≥ l·ªói
                        embedding_model = rate_manager.switch_to_next_key()
                        time.sleep(2)  # Ch·ªù 2s tr∆∞·ªõc khi retry
                    else:
                        print(f"‚ùå Th·∫•t b·∫°i sau {max_retries} attempts, b·ªè qua batch n√†y")
                        continue
            
            # Merge batch v√†o database ch√≠nh
            if 'batch_db' in locals():
                if db is None:
                    db = batch_db
                else:
                    db.merge_from(batch_db)
            
            # Hi·ªÉn th·ªã progress v√† status
            status = rate_manager.get_status()
            current_key_status = status['key_status'][status['current_key']-1]
            print(f"‚úÖ Processed {i+len(batch_texts)}/{len(texts)} rows | "
                  f"Key: {status['current_key']} | "
                  f"Usage: {current_key_status['usage']}/{REQUESTS_PER_KEY} | "
                  f"Requests/min: {current_key_status['requests_last_minute']}/{REQUESTS_PER_MINUTE} | "
                  f"Available keys: {status['total_available_keys']}/{len(rate_manager.api_keys)}")
            
        except Exception as e:
            print(f"‚ùå L·ªói nghi√™m tr·ªçng t·∫°i batch {i//batch_size + 1}: {str(e)}")
            continue
    
    if db is not None:
        db.save_local(faiss_folder)
        print(f"‚úÖ FAISS index saved to '{faiss_folder}'")
        print(f"üìä T·ªïng s·ªë requests ƒë√£ s·ª≠ d·ª•ng: {total_requests}")
        
        # Hi·ªÉn th·ªã th·ªëng k√™ cu·ªëi c√πng
        final_status = rate_manager.get_status()
        print(f"üìà Th·ªëng k√™ cu·ªëi c√πng:")
        for key_idx, key_status in final_status['key_status'].items():
            status_icon = "‚úÖ" if key_status['available'] else "‚è∏Ô∏è"
            print(f"   {status_icon} Key {key_idx + 1}: {key_status['usage']}/{REQUESTS_PER_KEY} requests "
                  f"(last min: {key_status['requests_last_minute']}/{REQUESTS_PER_MINUTE}) - {key_status['reason']}")
    else:
        print("‚ùå Kh√¥ng th·ªÉ t·∫°o FAISS index")
    
    return db

# --- Run ---
if __name__ == "__main__":
    print(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(texts)} texts v·ªõi {len(rate_manager.api_keys)} API keys")
    print(f"‚öôÔ∏è C·∫•u h√¨nh: {REQUESTS_PER_MINUTE} requests/ph√∫t, {REQUESTS_PER_KEY} requests/key")
    
    db = build_faiss_in_batches(texts, metadatas, rate_manager, FAISS_FOLDER, batch_size=10)
